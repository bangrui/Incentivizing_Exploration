\section{Proof of Lemma~\ref{lem:phase-length}}
\label{sec:lemma4-proof}

\begin{rlemma}{Lemma}{\ref{lem:phase-length}}
For any $s\geq 3$, the expected length of phase $s$ is at most
$\ARMNUM \cdot \log(s)$ time steps.
\end{rlemma}

\begin{proof}
Let $S$ be the set of arms that have been pulled at most
$s$ times at the start of phase $s$.
Thus, phase $s$ has ended when each $i \in S$ has been pulled at least once.
Consider any time step $t$.
If $S$ contains at least one payment-eligible arm $i$,
then some payment-eligible arm will be pulled with probability 1,
and every payment-eligible arm is in $S$.
In particular, the size of $S$ decreases with probability 1.
If $S$ contains no payment-eligible arm,
then by definition of payment-eligibility,
each arm $i \in S$ has probability at least $1/\log(s)$ of being pulled.
In particular, the size of $S$ decreases with probability at least $1/\log(s)$.

In either case, the expected number of time steps until
$|S|$ decreases is at most $\log s$,
so the expected number of steps until $S$ is empty is at most
$\ARMNUM \cdot \log(s)$.
\end{proof}







\section{Proof of Lemma~\ref{lem:round-prob}}
\label{sec:lemma5-proof}

\begin{rlemma}{Lemma}{\ref{lem:round-prob}}
Recall the noise is a mean-zero sub-Gaussian($\sigma^2$) random variable.
Let \LatePhase be a phase cutoff, 
and let $x_n, x'_n > 0$ be functions satisfying that
$\sqrt{0.6 n \cdot \log (\log_{1.1}(n) + 1) + \frac{n x_n^2}{16 \sigma^2}}
\leq \frac{n x'_n}{2 \sigma}$,
for all $n \geq \LatePhase$.
Let $\tau_s$ be a stopping time
(which may depend on the entire past history)
which is almost surely in phase $s$,
i.e., satisfying $\tau \in [t_s, t_{s+1})$ almost surely.

Then, for any arm $i$, attribute $j$, and phase $s \geq \LatePhase$,
we have that
$\Prob{\AccE{\tau_s}{i}{j}{x'_s}}
\geq 1 - 24 \exp\left(-\frac{1.8 s x_s^2}{16 \sigma^2} \right)$.
\end{rlemma}

The proof of Lemma~\ref{lem:round-prob} is based on an adaptive
concentration inequality due to \cite{zhao2016adaptive},
given as Lemma~\ref{lem:ACI-inequality}.

\begin{lemma}[Corollary 1 of \cite{zhao2016adaptive}]
\label{lem:ACI-inequality}
Let $X_i$ be zero-mean $1/2$-subgaussian random variables,
and $\SET{S_n = \sum_{i=1}^n X_i, n \geq 1}$ the corresponding random walk.
Let $J$ be any stopping time with respect to $\SET{X_1, X_2, \ldots}$.
(We allow $J$ to take the value $\infty$,
defining $\Prob{J = \infty} = 1 - \lim_{n \to \infty} \Prob{J \leq n}$.)
Define 
$g(n)  = \sqrt{0.6 n \cdot \log (\log_{1.1}(n) + 1) + n \cdot b}$.

Then, 
$\Prob{J < \infty \mbox{ and } S_J \geq g(J)} \leq 12 \e^{-1.8 b}$.
\end{lemma}

\begin{extraproof}{Lemma~\ref{lem:round-prob}}
Fix an arm $i$ and attribute $j$.
By the assumptions of the lemma,
the stopping time $\tau_s$ is such that almost surely,
each arm --- and in particular arm $i$ --- has been pulled at least
$s \geq \LatePhase$ times at time $\tau_s$.
Define $J$ to be the number of times that $i$ has been pulled at
time $\tau_s$.
For any $n \geq 1$, let $k_n$ be the time step right after arm $i$ has
been pulled for the \Kth{n} time. Define
$S_n := \frac{n \cdot (\ArmE{k_n}{i}{j} - \Arm{i}{j})}{2 \sigma}$
to be the sum of all attribute-$j$ noise components up to and
including the \Kth{n} pull of arm $i$,
renormalized to be a mean-zero sub-Gaussian($1/2$) random variable.
The $S_n$ define an unbiased half-subgaussian random walk,
and we can therefore apply Lemma~\ref{lem:ACI-inequality} to them and
the stopping time $J$.
Specifically, we set $b = \frac{x_J^2}{16 \sigma^2}$,
and obtain that

\begin{align*}
\Prob{J < \infty \mbox{ and } S_J \geq 
\sqrt{0.6 J \cdot \log (\log_{1.1}(J) + 1) + \frac{J x_J^2}{16 \sigma^2}}}
& \leq 12 \exp \left( \frac{-1.8 J x_J^2}{16 \sigma^2} \right).
\end{align*}

Applying Lemma~\ref{lem:ACI-inequality} to $-S_n$ with the same choice
of $b$, and taking a union bound over both cases, we obtain that

\begin{align*}
\Prob{J < \infty \mbox{ and } |S_J| \geq 
\sqrt{0.6 J \cdot \log (\log_{1.1}(J) + 1) + \frac{J x_J^2}{16 \sigma^2}}}
& \leq 24 \exp \left( \frac{-1.8 J x_J^2}{16 \sigma^2} \right).
\end{align*}

Because $J$ will be finite with probability 1, we can drop the
$J < \infty$ part of the event:
\begin{align*}
& \Prob{S_J \geq 
\sqrt{0.6 J \cdot \log (\log_{1.1}(J) + 1) + \frac{J^2 x_J^2}{16
    \sigma^2}}}\\
= & \Prob{J < \infty \mbox{ and } S_J \geq 
\sqrt{0.6 J \cdot \log (\log_{1.1}(J) + 1) + \frac{J^2 x_J^2}{16
    \sigma^2}}}.
\end{align*}

In the high-probability case, we now apply the assumed inequality
between $x_J$ and $x'_J$, to obtain that
\[
|S_J| \; \leq \;
\sqrt{0.6 J \cdot \log (\log_{1.1}(J) + 1) + \frac{J x_J^2}{16 \sigma^2}}
\; \leq \; \frac{J x'_J}{2 \sigma}.
\]

Substituting the definition of $S_J$ and canceling common terms,
the inequality implies that
$|\ArmE{k_J}{i}{j} - \Arm{i}{j}| \leq x'_J$.
The choice of $J$ ensures that
$\ArmE{k_J}{i}{j} = \ArmE{\tau_s}{i}{j}$,
and we have thus shown that
$|\ArmE{\tau_s}{i}{j} - \Arm{i}{j}| \leq x'_s$.
\end{extraproof}




\section{Proof of Lemma~\ref{lem:right-choice}}
\label{sec:lemma7-proof}

\begin{rlemma}{Lemma}{\ref{lem:right-choice}}
Let $x > 0$ be arbitrary.
When \AccEU{t}{x} happens,
no agent \AgV will pull a highly suboptimal arm, i.e., an arm $i$ with 
$\AgV \cdot (\ArmV{\Best{\AgV}} - \ArmV{i}) > 2\Diam d x$.
\end{rlemma}

\begin{proof}
By definition, when \AccEU{t}{x} happens,
for all arms $i$ and attributes $j$,
all arm attribute estimates are accurate to within $x$,
in the sense that
$|\ArmE{t}{i}{j} - \Arm{i}{j}| \leq x$.

Consider any agent type \AgV.
Let $i \neq \Best{\AgV}$ be any arm
with much smaller true reward than the best arm:
$\AgV \cdot (\ArmV{\Best{\AgV}} - \ArmV{i}) > 2\Diam d x$.
Because each coordinate of \ArmEV{t}{\Best{\AgV}} and of
\ArmEV{t}{i} is estimated accurately to within $x$, 
we get that 
$\AgV \cdot (\ArmEV{t}{\Best{\AgV}} - \ArmV{\Best{\AgV}})
\geq - \Diam d x$
and
$\AgV \cdot (\ArmEV{t}{i} - \ArmV{i}) \leq \Diam d x$.
Hence, 

\begin{align}
\AgV \cdot (\ArmEV{t}{\Best{\AgV}} - \ArmEV{t}{i})
& =
\AgV \cdot (\ArmEV{t}{\Best{\AgV}} - \ArmV{\Best{\AgV}})
+ \AgV \cdot (\ArmV{\Best{\AgV}} - \ArmV{i})
+ \AgV \cdot (\ArmV{i} - \ArmEV{t}{i}) \nonumber\\
& > -\Diam d x + 2 \Diam d x - \Diam d x
\; = \; 0, \label{equ:choice}
\end{align}
which means that the agent with type \AgV will not pull arm $i$.
\end{proof}


\section{Proof of Lemma~\ref{lem:no-incentives}}
\label{sec:lemma8-proof}

\begin{rlemma}{Lemma}{\ref{lem:no-incentives}}
Fix an arm $i$.
Let $s \geq \exp(2/\MinProb)$, and let $\tau_s$ be the (random)
time when arm $i$ is pulled for the \Kth{s} time.
Let $\hat{x} = \frac{1}{2\Diam d}
  \cdot \min(\TieCutoff, \frac{\MinProb}{2\TieDensity})$.
Under \AccEU{\tau_s}{\hat{x}},
this pull of arm $i$ is not incentivized.
\end{rlemma}

\begin{proof}
By Lemma~\ref{lem:right-choice},
under the event \AccEU{\tau_s}{\hat{x}},
all agent types \AgV with
$\AgV \cdot (\ArmV{\Best{\AgV}} - \ArmV{\Second{\AgV}})
> 2\Diam d \hat{x}$
will pull their best arm \Best{\AgV}.
Notice that $2\Diam d \hat{x}
= \min(\TieCutoff, \frac{\MinProb}{2 \TieDensity})$

By Assmption~\ref{A1},
the measure of agents (across all arms)
whose best and second-best arm differ in utility by less
than $\min(\TieCutoff, \frac{\MinProb}{2 \TieDensity})$
is at most
$\TieDensity \cdot \min(\TieCutoff, \frac{\MinProb}{2 \TieDensity})
\leq \frac{\MinProb}{2}$.
In particular, this bound holds for agents whose best arm is $i$.
By Assumption~\ref{A3}, at least a measure \MinProb of agents has $i$
as their best arm, and thus, at least a measure $\frac{\MinProb}{2}$
will myopically pull arm $i$.
Because $1/\log(s) \leq \frac{\MinProb}{2}$ for
$s \geq \exp(2/\MinProb)$, arm $i$ is not payment-eligible at time
$\tau_s$.
\end{proof}
