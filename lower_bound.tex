\section{A Lower Bound of $\Omega(\log(T))$} \label{sec:lb}

We saw in Corollary~\ref{cor:constant-regret} that
when agent preferences for their best arm are sufficiently clear,
in the sense that $\TieDensity = 0$, the regret of
Algorithm~\ref{alg:basic-incentivizing} is bounded by a constant.
One may conjecture that this should hold more generally,
in that that regret of the (fewer and fewer) agents on the boundary
between close arms should go to 0, while their fraction also goes to 0.
In this section, we establish a lower bound,
showing that even in very simple settings, a (logarithmic) dependence
on $T$ is typicaly unavoidable for \emph{any} incentivization strategy.

We consider an instance with two arms,
whose attribute vectors are $(0,0)$ and $(0,1)$, respectively.
Agents types are distributed uniformly on the two-dimensional unit circle%
\footnote{While our model technically assumed that all agent coordinates are
non-negative, we could simply shift the unit circle.
The present choice is solely for ease of notation.}  
$\Set{\AgV}{|| \AgV ||_2 \leq 1}$.
Because $\AgV \cdot (0,0) = 0$ and $\AgV \cdot (0,1) = \Ag{2}$,
the best choice for agent \AgV is arm $(0,1)$ iff $\Ag{2} > 0$,
i.e., the top half of the unit circle prefers the arm $(0,1)$,
and the bottom half prefers the arm $(0,0)$.

Since we are proving a lower bound, we give the algorithm the
following extra two advantages:
(1) there is no noise in the observations of the arm $(0,0)$,
and all agents know its location deterministically.
(2) in each time step, regardless of which arm is pulled, the algorithm
and all agents observe a pull from arm $(0,1)$.
For simplicity of notation, we set the standard deviation of the arm
$(0,1)$ to $\sigma = 1$; different values only lead to a scaling of
the results.

Under these advantages, myopic play is clearly optimal, so it suffices
to bound the regret of the myopic algorithm which never incentivizes
agents. \dkcomment{This feels ``clear'', but is it?}

Because a pull of arm $(0,1)$ is observed in each time step,
after $t$ rounds, the estimate \ArmEV{t}{(0,1)} is of the form
$(0,1) + (\Noise[t]{1}, \Noise[t]{2})$,
where $\Noise[t]{1} \sim \Normal{0}{\sqrt{1/t}}$
and $\Noise[t]{2} \sim \Normal{0}{\sqrt{1/t}})$.
\dkcomment{I think we define this to be the estimates at the beginning
  of round $t$, so we may be off by 1 here and in other places.}
We lower-bound the regret in step $t$ by focusing on the event that
both normal noise coordinates are non-negative,
which by symmetry has probability \quarter:

\begin{align*}
\Expect{\Regret{t}} 
  & \geq \ExpectC{\Regret{t}}{\Noise[t]{1} > 0, \Noise[t]{2} > 0}
         \cdot \Prob{\Noise[t]{1} > 0, \Noise[t]{2} > 0}
  \; = \; \quarter \ExpectC{\Regret{t}}{\Noise[t]{1} > 0, \Noise[t]{2} > 0}.
\end{align*}

For the moment, focus on some time step $t$,
and write $\NoiseV = \NoiseV[t]$.
Then, there are two types of agents who pull the wrong arm and incur
regret:
\begin{enumerate}
\item If $\Ag{2} > 0$ and $\Ag{1} \Noise{1} + \Ag{2} (1+\Noise{2}) < 0$
then \AgV should pull $(0,1)$,
but will wrongly pull $(0,0)$ and incur regret \Ag{2}.
The region
$\Ag{2} > 0$ and $\Ag{1} < \frac{-(1+\Noise{2})}{\Noise{1}} \cdot \Ag{2}$
defines a wedge.
For any particular value of \Ag{2},
the length of the interval of corresponding \Ag{1} is
\begin{align*}
  \sqrt{1-\Ag{2}^2} - \frac{1+\Noise{2}}{\Noise{1}} \cdot \Ag{2}
  & \geq 1 - \Ag{2} - \frac{1+\Noise{2}}{\Noise{1}} \cdot \Ag{2}
  \; = \; 1 - \frac{1+\Noise{1}+\Noise{2}}{\Noise{1}} \cdot \Ag{2}.
\end{align*}

\item If $\Ag{2} < 0$ and $\Ag{1} \Noise{1} + \Ag{2} (1+\Noise{2}) > 0$,
then \Ag should pull $(0,0)$,
but will wrongly pull $(0,1)$ and incur regret $-\Ag{2}$.
This region and its regret are rotationally symmetric to the previous
case.
\end{enumerate}

Hence, the expected regret for given \Noise{1}, \Noise{2} is at least
\begin{align*}
  2 \int_0^{\frac{\Noise{1}}{1+\Noise{1}+\Noise{2}}}
  \left( 1 - \frac{1+\Noise{1}+\Noise{2}}{\Noise{1}} \cdot \Ag{2} \right)
  \cdot \Ag{2} \cdot \frac{1}{\pi} \dd \Ag{2}
& =
\frac{1}{\pi} \cdot \left(\frac{\Noise{1}}{1+\Noise{1}+\Noise{2}}\right)^2
- \frac{2}{3 \pi} \cdot \left(\frac{\Noise{1}}{1+\Noise{1}+\Noise{2}}\right)^2
\\ & =
\frac{1}{3 \pi} \cdot \left(\frac{\Noise{1}}{1+\Noise{1}+\Noise{2}}\right)^2.
\end{align*}

\begin{align}
&E[r(t)| \Noise{1}>0, \Noise{2}>0] \nonumber \\
\geq & 4\times \frac{1}{3\pi} \int_{0}^{\infty} \int_{0}^{\infty} (\frac{\Noise{1}}{1+\Noise{1}+\Noise{2}})^2\frac{e^{-\frac{t \times \Noise{1}^2}{2}}\sqrt{t}}{\sqrt{2\pi}}d(\Noise{1})\frac{e^{-\frac{t \times \Noise{2}^2}{2}}\sqrt{t}}{\sqrt{2\pi}}d(\Noise{2}) \nonumber \\
= & \frac{1}{3\pi^3} \int_{0}^{\infty} \int_{0}^{\infty} (\frac{\Noise{1}}{\sqrt{t}+\Noise{1}+\Noise{2}})^2e^{-\frac{\Noise{1}^2}{2}}d(\Noise{1})e^{-\frac{\Noise{2}^2}{2}}d(\Noise{2}) \nonumber 
\end{align}

Below, we want to show 
\begin{align}
\lim_{t\rightarrow\infty}\frac{E[r(t)| \Noise{1}>0, \Noise{2}>0]}{\frac{1}{t}} = \Omega(1), \nonumber
\end{align}
and use the fact that $\sum_{n=1}^{T}\frac{1}{n}=\Omega(\log(T))$ to show the regret is at least $\Omega(\log(T))$. Since
\begin{align}
&\lim_{t\rightarrow \infty}\frac{E[r(t)| \Noise{1}>0, \Noise{2}>0]}{\frac{1}{t}} \nonumber \\
\geq & \lim_{t\rightarrow \infty}\frac{1}{3\pi^3}\int_{0}^{\infty} \int_{0}^{\infty}\left[ t(\frac{\Noise{1}}{\sqrt{t}+\Noise{1}+\Noise{2}})^2\right]e^{-\frac{\Noise{1}^2}{2}}e^{-\frac{\Noise{2}^2}{2}}d(\Noise{1})d(\Noise{2}) \nonumber  \\
= & \frac{1}{3\pi^3}\int_{0}^{\infty} \int_{0}^{\infty}\lim_{t\rightarrow \infty}\left[ t(\frac{\Noise{1}}{\sqrt{t}+\Noise{1}+\Noise{2}})^2\right]e^{-\frac{\Noise{1}^2}{2}}e^{-\frac{\Noise{2}^2}{2}}d(\Noise{1})d(\Noise{2}) \nonumber  \\
=&\frac{1}{3\pi^3}\int_{0}^{\infty} \int_{0}^{\infty}e^{-\frac{\Noise{1}^2}{2}}e^{-\frac{\Noise{2}^2}{2}}d(\Noise{1})d(\Noise{2}) = \frac{1}{3\pi^3}, \nonumber
\end{align}

where the third line is due to monotone convergence theorem since the derivative of $t(\frac{\Noise{1}}{\sqrt{t}+\Noise{1}+\Noise{2}})^2$ is greater than $0$.



\dkcomment{I edited up to here. Waiting for some feedback about
  whether my calculations are way off.
  I did use one bound of $\sqrt{1-\Ag{2}^2} \geq 1-\Ag{2}$, but since
  we are looking at small values of \Ag{2}, I cannot imagine that this
  lost much. One can compute the integral without this simplification,
  but it will be quite a bit uglier.} 
 
